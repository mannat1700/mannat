{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\names.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female.txt', 'male.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2943\n"
     ]
    }
   ],
   "source": [
    "print(len(names.words('male.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001\n"
     ]
    }
   ],
   "source": [
    "print(len(names.words('female.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aamir',\n",
       " 'Aaron',\n",
       " 'Abbey',\n",
       " 'Abbie',\n",
       " 'Abbot',\n",
       " 'Abbott',\n",
       " 'Abby',\n",
       " 'Abdel',\n",
       " 'Abdul',\n",
       " 'Abdulkarim',\n",
       " 'Abdullah',\n",
       " 'Abe',\n",
       " 'Abel',\n",
       " 'Abelard',\n",
       " 'Abner']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.words('male.txt')[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abagael',\n",
       " 'Abagail',\n",
       " 'Abbe',\n",
       " 'Abbey',\n",
       " 'Abbi',\n",
       " 'Abbie',\n",
       " 'Abby',\n",
       " 'Abigael',\n",
       " 'Abigail',\n",
       " 'Abigale',\n",
       " 'Abra',\n",
       " 'Acacia',\n",
       " 'Ada',\n",
       " 'Adah',\n",
       " 'Adaline']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.words('female.txt')[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of stopwords in English:\n",
      "{'now', \"you'd\", 'ourselves', 'yourselves', 'mightn', 'to', 'up', 'hers', 'before', 'below', 'it', 'own', 'we', 'him', 'his', 'had', 'on', 'wasn', 'wouldn', \"shouldn't\", 'out', 'ours', 'her', 'this', 'themselves', 'couldn', 'at', 'those', 'does', 'do', 'too', \"she's\", 'again', 'and', 'because', 'not', 'no', 'yourself', 'some', 'shouldn', 'aren', 'is', 'have', 'hadn', 'theirs', 'that', 're', 'so', 'if', 'each', 'm', 'off', 'they', 't', 'been', \"should've\", 'over', 'd', 'against', 'which', 'o', 'yours', 'hasn', 'haven', 'be', 'nor', 'did', 'by', 'don', 'their', 'our', \"shan't\", 'me', \"mustn't\", 'you', 'its', 'through', 've', 'has', 'in', 'here', 'mustn', 'there', 'them', \"you've\", 'after', 'these', 'why', 'didn', \"you're\", 'was', 'only', \"doesn't\", 'having', 'any', \"hadn't\", \"that'll\", 'y', 'from', 's', 'more', \"hasn't\", 'how', \"didn't\", 'will', 'above', 'll', 'the', 'where', 'about', 'for', 'with', 'then', 'very', 'himself', 'such', 'doing', 'he', 'ma', 'what', \"needn't\", 'during', 'myself', \"don't\", 'under', 'am', \"aren't\", 'few', 'most', \"couldn't\", 'other', 'further', 'shan', \"won't\", 'or', 'a', 'same', 'an', 'of', 'are', 'but', 'until', 'into', 'being', 'isn', 'weren', 'all', 'as', 'were', 'than', 'my', 'whom', 'down', \"you'll\", 'should', \"isn't\", \"wasn't\", \"mightn't\", \"wouldn't\", 'both', 'while', 'between', \"weren't\", 'won', 'itself', 'when', 'your', 'she', 'once', 'herself', 'just', \"haven't\", 'can', 'doesn', \"it's\", 'ain', 'i', 'needn', 'who'}\n",
      "\n",
      "Omit - 'to', 'some' and 'yourself':\n",
      "\n",
      "List of fresh stopwords in English:\n",
      "{'now', \"you'd\", 'ourselves', 'yourselves', 'mightn', 'to', 'up', 'hers', 'before', 'below', 'it', 'own', 'we', 'him', 'his', 'had', 'on', 'wasn', 'wouldn', \"shouldn't\", 'out', 'ours', 'her', 'this', 'themselves', 'couldn', 'at', 'those', 'does', 'do', 'too', \"she's\", 'and', 'because', 'not', 'no', 'yourself', 'some', 'shouldn', 'aren', 'is', 'have', 'hadn', 'theirs', 'that', 're', 'so', 'if', 'each', 'm', 'off', 'they', 't', 'been', \"should've\", 'over', 'd', 'against', 'which', 'o', 'yours', 'hasn', 'haven', 'be', 'nor', 'did', 'by', 'don', 'their', 'our', \"shan't\", 'me', \"mustn't\", 'you', 'its', 'through', 've', 'has', 'in', 'here', 'mustn', 'there', 'them', \"you've\", 'after', 'these', 'why', 'didn', \"you're\", 'was', 'only', \"doesn't\", 'having', 'any', \"hadn't\", \"that'll\", 'y', 's', 'more', \"hasn't\", 'how', \"didn't\", 'will', 'above', 'll', 'the', 'where', 'about', 'for', 'with', 'then', 'very', 'himself', 'such', 'doing', 'he', 'ma', 'what', \"needn't\", 'during', 'myself', \"don't\", 'under', 'am', \"aren't\", 'few', 'most', \"couldn't\", 'other', 'further', 'shan', \"won't\", 'or', 'a', 'same', 'an', 'of', 'are', 'but', 'until', 'into', 'being', 'isn', 'weren', 'all', 'as', 'were', 'than', 'my', 'whom', 'down', \"you'll\", 'should', \"isn't\", \"wasn't\", \"mightn't\", \"wouldn't\", 'both', 'while', 'between', \"weren't\", 'won', 'itself', 'when', 'your', 'she', 'herself', 'just', \"haven't\", 'can', 'doesn', \"it's\", 'ain', 'i', 'needn', 'who'}\n"
     ]
    }
   ],
   "source": [
    "words = set(stopwords.words('english'))\n",
    "print(\"List of stopwords in English:\")\n",
    "print(words)\n",
    "print(\"\\nOmit - 'to', 'some' and 'yourself':\")\n",
    "stop_words = set(stopwords.words('english')) - set(['again', 'once', 'from'])\n",
    "print(\"\\nList of fresh stopwords in English:\")\n",
    "print (stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\manna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defination of the said word:\n",
      "an instance or single occasion for some event\n",
      "\n",
      "Examples of the word in use::\n",
      "['this time he succeeded', 'he called four times', 'he could do ten at a clip']\n"
     ]
    }
   ],
   "source": [
    "syns = wordnet.synsets(\"time\")\n",
    "print(\"Defination of the said word:\")\n",
    "print(syns[0].definition())\n",
    "print(\"\\nExamples of the word in use::\")\n",
    "print(syns[0].examples())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carlota\n",
      "Raychel\n",
      "Harlene\n",
      "Tyrus\n",
      "Tony\n",
      "Stacy\n",
      "Shoshie\n",
      "Tomasine\n",
      "Dolly\n",
      "Piggy\n",
      "Harrison\n",
      "Lelah\n",
      "Giana\n",
      "Hayes\n",
      "Maure\n",
      "Salomo\n",
      "Lorettalorna\n",
      "Kaile\n",
      "Caterina\n",
      "Jobey\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "r = names.words('male.txt')+names.words('female.txt')\n",
    "for i in range(20):\n",
    "    print(random.choice(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Keri', 'female'), ('Nat', 'female'), ('Lyndsey', 'female'), ('Melisande', 'female'), ('Enrica', 'female'), ('Liora', 'female'), ('Zalman', 'male'), ('Rockwell', 'male'), ('Broderick', 'male'), ('Marcella', 'female'), ('Jilli', 'female'), ('Waleed', 'male'), ('Ulrika', 'female'), ('Adelind', 'female'), ('Delcina', 'female'), ('Ilona', 'female'), ('Oleg', 'male'), ('Coraline', 'female'), ('Orson', 'male'), ('Tarzan', 'male')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import names \n",
    "import random \n",
    " \n",
    "male_names = names.words('male.txt')\n",
    "female_names = names.words('female.txt')\n",
    " \n",
    "labeled_male_names = [(str(name), 'male') for name in male_names]\n",
    "labeled_female_names = [(str(name), 'female') for name in female_names]\n",
    "\n",
    "\n",
    "labeled_all_names = labeled_male_names + labeled_female_names\n",
    " \n",
    "\n",
    "random.shuffle(labeled_all_names)\n",
    " \n",
    "print (labeled_all_names[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'was', 'the', 'best', 'of', 'times', ',', 'it', 'was', 'the', 'worst', 'of', 'times', ',', 'it', 'was', 'the', 'age', 'of', 'wisdom', ',', 'it', 'was', 'the', 'age', 'of', 'foolishness', ',', 'it', 'was', 'the', 'epoch', 'of', 'belief', ',', 'it', 'was', 'the', 'epoch', 'of', 'incredulity', ',', 'it', 'was', 'the', 'season', 'of', 'Light', ',', 'it', 'was', 'the', 'season', 'of', 'Darkness', ',', 'it', 'was', 'the', 'spring', 'of', 'hope', ',', 'it', 'was', 'the', 'winter', 'of', 'despair', '.']\n",
      "['best', 'times', ',', 'worst', 'times', ',', 'age', 'wisdom', ',', 'age', 'foolishness', ',', 'epoch', 'belief', ',', 'epoch', 'incredulity', ',', 'season', 'Light', ',', 'season', 'Darkness', ',', 'spring', 'hope', ',', 'winter', 'despair', '.']\n",
      "[(',', 9), ('times', 2), ('age', 2), ('epoch', 2), ('season', 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\manna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "text = 'It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness,it was the epoch of belief, it was the epoch of incredulity,it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair.'\n",
    "words = nltk.word_tokenize(text)\n",
    "print(words)\n",
    "words = [w for w in words if w.lower() not in stopwords]\n",
    "print(words)\n",
    "\n",
    "fd = nltk.FreqDist(words)\n",
    "print(fd.most_common(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'آه',\n",
       " 'آها',\n",
       " 'آي',\n",
       " 'أف',\n",
       " 'أقل',\n",
       " 'أكثر',\n",
       " 'ألا',\n",
       " 'أم',\n",
       " 'أما',\n",
       " 'أن',\n",
       " 'أنا',\n",
       " 'أنت',\n",
       " 'أنتم',\n",
       " 'أنتما',\n",
       " 'أنتن',\n",
       " 'أنى',\n",
       " 'أو',\n",
       " 'أولئك',\n",
       " 'أولاء',\n",
       " 'أوه',\n",
       " 'أي',\n",
       " 'أين',\n",
       " 'أينما',\n",
       " 'أيها',\n",
       " 'إذ',\n",
       " 'إذا',\n",
       " 'إذما',\n",
       " 'إذن',\n",
       " 'إلا',\n",
       " 'إلى',\n",
       " 'إليك',\n",
       " 'إليكم',\n",
       " 'إليكما',\n",
       " 'إليكن',\n",
       " 'إما',\n",
       " 'إن',\n",
       " 'إنا',\n",
       " 'إنما',\n",
       " 'إنه',\n",
       " 'إي',\n",
       " 'إيه',\n",
       " 'التي',\n",
       " 'الذي',\n",
       " 'الذين',\n",
       " 'اللائي',\n",
       " 'اللاتي',\n",
       " 'اللتان',\n",
       " 'اللتيا',\n",
       " 'اللتين',\n",
       " 'اللذان',\n",
       " 'اللذين',\n",
       " 'اللواتي',\n",
       " 'بخ',\n",
       " 'بس',\n",
       " 'بعد',\n",
       " 'بعض',\n",
       " 'بك',\n",
       " 'بكم',\n",
       " 'بكما',\n",
       " 'بكن',\n",
       " 'بل',\n",
       " 'بلى',\n",
       " 'بما',\n",
       " 'بماذا',\n",
       " 'بمن',\n",
       " 'بنا',\n",
       " 'به',\n",
       " 'بها',\n",
       " 'بهم',\n",
       " 'بهما',\n",
       " 'بهن',\n",
       " 'بي',\n",
       " 'بيد',\n",
       " 'بين',\n",
       " 'تلك',\n",
       " 'تلكم',\n",
       " 'تلكما',\n",
       " 'ته',\n",
       " 'تي',\n",
       " 'تين',\n",
       " 'تينك',\n",
       " 'ثم',\n",
       " 'ثمة',\n",
       " 'حاشا',\n",
       " 'حبذا',\n",
       " 'حتى',\n",
       " 'حيث',\n",
       " 'حيثما',\n",
       " 'حين',\n",
       " 'خلا',\n",
       " 'دون',\n",
       " 'ذا',\n",
       " 'ذات',\n",
       " 'ذاك',\n",
       " 'ذان',\n",
       " 'ذانك',\n",
       " 'ذلك',\n",
       " 'ذلكم',\n",
       " 'ذلكما',\n",
       " 'ذلكن',\n",
       " 'ذه',\n",
       " 'ذو',\n",
       " 'ذوا',\n",
       " 'ذواتا',\n",
       " 'ذواتي',\n",
       " 'ذي',\n",
       " 'ذين',\n",
       " 'ذينك',\n",
       " 'ريث',\n",
       " 'سوف',\n",
       " 'سوى',\n",
       " 'شتان',\n",
       " 'عدا',\n",
       " 'عسى',\n",
       " 'عل',\n",
       " 'على',\n",
       " 'عليك',\n",
       " 'عليه',\n",
       " 'عما',\n",
       " 'عن',\n",
       " 'عند',\n",
       " 'غير',\n",
       " 'فإذا',\n",
       " 'فإن',\n",
       " 'فلا',\n",
       " 'فمن',\n",
       " 'في',\n",
       " 'فيم',\n",
       " 'فيما',\n",
       " 'فيه',\n",
       " 'فيها',\n",
       " 'قد',\n",
       " 'كأن',\n",
       " 'كأنما',\n",
       " 'كأي',\n",
       " 'كأين',\n",
       " 'كذا',\n",
       " 'كذلك',\n",
       " 'كل',\n",
       " 'كلا',\n",
       " 'كلاهما',\n",
       " 'كلتا',\n",
       " 'كلما',\n",
       " 'كليكما',\n",
       " 'كليهما',\n",
       " 'كم',\n",
       " 'كما',\n",
       " 'كي',\n",
       " 'كيت',\n",
       " 'كيف',\n",
       " 'كيفما',\n",
       " 'لئن',\n",
       " 'لا',\n",
       " 'لاسيما',\n",
       " 'لدى',\n",
       " 'لست',\n",
       " 'لستم',\n",
       " 'لستما',\n",
       " 'لستن',\n",
       " 'لسن',\n",
       " 'لسنا',\n",
       " 'لعل',\n",
       " 'لك',\n",
       " 'لكم',\n",
       " 'لكما',\n",
       " 'لكن',\n",
       " 'لكنما',\n",
       " 'لكي',\n",
       " 'لكيلا',\n",
       " 'لم',\n",
       " 'لما',\n",
       " 'لن',\n",
       " 'لنا',\n",
       " 'له',\n",
       " 'لها',\n",
       " 'لهم',\n",
       " 'لهما',\n",
       " 'لهن',\n",
       " 'لو',\n",
       " 'لولا',\n",
       " 'لوما',\n",
       " 'لي',\n",
       " 'ليت',\n",
       " 'ليس',\n",
       " 'ليسا',\n",
       " 'ليست',\n",
       " 'ليستا',\n",
       " 'ليسوا',\n",
       " 'ما',\n",
       " 'ماذا',\n",
       " 'متى',\n",
       " 'مذ',\n",
       " 'مع',\n",
       " 'مما',\n",
       " 'ممن',\n",
       " 'من',\n",
       " 'منذ',\n",
       " 'منه',\n",
       " 'منها',\n",
       " 'مه',\n",
       " 'مهما',\n",
       " 'نحن',\n",
       " 'نحو',\n",
       " 'نعم',\n",
       " 'هؤلاء',\n",
       " 'ها',\n",
       " 'هاتان',\n",
       " 'هاته',\n",
       " 'هاتي',\n",
       " 'هاتين',\n",
       " 'هاك',\n",
       " 'هاهنا',\n",
       " 'هذا',\n",
       " 'هذان',\n",
       " 'هذه',\n",
       " 'هذي',\n",
       " 'هذين',\n",
       " 'هكذا',\n",
       " 'هل',\n",
       " 'هلا',\n",
       " 'هم',\n",
       " 'هما',\n",
       " 'هن',\n",
       " 'هنا',\n",
       " 'هناك',\n",
       " 'هنالك',\n",
       " 'هو',\n",
       " 'هي',\n",
       " 'هيا',\n",
       " 'هيت',\n",
       " 'هيهات',\n",
       " 'وإذ',\n",
       " 'وإذا',\n",
       " 'وإن',\n",
       " 'والذي',\n",
       " 'والذين',\n",
       " 'ولا',\n",
       " 'ولكن',\n",
       " 'ولو',\n",
       " 'وما',\n",
       " 'ومن',\n",
       " 'وهو',\n",
       " 'يا'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "arabic_stopwords = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "arabic_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
